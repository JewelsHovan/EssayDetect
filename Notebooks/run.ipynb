{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import google.generativeai as palm\n",
    "import uuid\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PalmLLM:\n",
    "    def __init__(self, api_key=None):\n",
    "        self.api_key = api_key or 'YOUR_PALM_API_KEY'\n",
    "        palm.configure(api_key=self.api_key)\n",
    "\n",
    "    def generate_text(self, prompt, source_text):\n",
    "        \"\"\"\n",
    "        Generates text based on a given prompt and source text using Google's PaLM model.\n",
    "\n",
    "        :param prompt: The prompt for the text generation.\n",
    "        :param source_text: The source text related to the prompt.\n",
    "        \"\"\"\n",
    "        response = palm.chat(\n",
    "            model='models/chat-bison-001',  # Replace with the specific PaLM model you intend to use\n",
    "            messages= f\"{prompt}\\n\\n{source_text} No title headers or bullet points, only paragraphs of text\",\n",
    "            temperature=1,\n",
    "            candidate_count=1\n",
    "        )\n",
    "\n",
    "        # Accessing the generated text from the response\n",
    "        generated_response = response.candidates[0]['content']\n",
    "        clean_text = re.sub(r'\\n+', '\\n', generated_response)  # Remove extra new lines\n",
    "        # Additional cleaning or processing can be added here\n",
    "\n",
    "        return clean_text\n",
    "\n",
    "    def generate_texts(self, n, prompts_df):\n",
    "        \"\"\"\n",
    "        Generates multiple texts using the PaLM model.\n",
    "\n",
    "        :param n: Number of iterations to generate texts.\n",
    "        :param prompts_df: DataFrame containing prompts and source texts.\n",
    "        \"\"\"\n",
    "        generated_texts = []\n",
    "        for _ in range(n):\n",
    "            for _, row in prompts_df.iterrows():\n",
    "                prompt_id = row['prompt_id']\n",
    "                source_text = row['source_text']\n",
    "\n",
    "                generated_text = self.generate_text(row['instructions'], source_text)\n",
    "                text_id = str(uuid.uuid4())[:8]  # Generate a unique ID for each text\n",
    "                generated_texts.append([text_id, prompt_id, generated_text, 1])\n",
    "\n",
    "        generated_df = pd.DataFrame(generated_texts, columns=['id', 'prompt_id', 'text', 'generated'])\n",
    "        return generated_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id  prompt_id                                               text  \\\n",
      "0  dfeeafe5          0  **The Advantages of Limiting Car Usage**\\nCars...   \n",
      "1  f555b1c8          1  Dear Senator,\\nI am writing to you today to ex...   \n",
      "2  ceae5497          0  In recent years, there has been a growing tren...   \n",
      "3  d12b8d86          1  Dear Senator,\\nI am writing to you today to ex...   \n",
      "4  75b0b795          0  The advantages of limiting car usage are numer...   \n",
      "\n",
      "   generated  \n",
      "0          1  \n",
      "1          1  \n",
      "2          1  \n",
      "3          1  \n",
      "4          1  \n"
     ]
    }
   ],
   "source": [
    "n = 200 # Number of iterations to generate texts\n",
    "train_prompts_path = 'LLM Detect AI Generated Text/train_prompts.csv'\n",
    "prompts_df = pd.read_csv(train_prompts_path)\n",
    "palm_llm = PalmLLM(api_key='AIzaSyD8SIvsEu0zHP8j6FHt44WMX_10yV_VnSY')\n",
    "\n",
    "df_generated = palm_llm.generate_texts(n, prompts_df)\n",
    "print(df_generated.head())\n",
    "df_generated.to_csv('Palm_generated_texts2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           id  prompt_id                                               text  \\\n",
      "0    58d8e644          0  The following are some of the advantages of li...   \n",
      "1    4e5899c1          1  Dear State Senator,\\nI am writing to you today...   \n",
      "2    a1913441          0  ## Advantages of Limiting Car Usage\\nCars have...   \n",
      "3    6c69eb76          1  Dear Senator,\\nI am writing to you today to ex...   \n",
      "4    5014eb83          0  The following are some of the advantages of li...   \n",
      "..        ...        ...                                                ...   \n",
      "195  c01f4705          1  Dear State Senator,\\nI am writing to express m...   \n",
      "196  ba221160          0  Limiting car usage has numerous advantages for...   \n",
      "197  243ad700          1  Dear State Senator,\\nI am writing to express m...   \n",
      "198  2ad11e88          0  In recent years, there has been a growing move...   \n",
      "199  2550e6ec          1  Dear Senator,\\nI am writing to express my supp...   \n",
      "\n",
      "     generated  \n",
      "0            1  \n",
      "1            1  \n",
      "2            1  \n",
      "3            1  \n",
      "4            1  \n",
      "..         ...  \n",
      "195          1  \n",
      "196          1  \n",
      "197          1  \n",
      "198          1  \n",
      "199          1  \n",
      "\n",
      "[1300 rows x 4 columns]\n",
      "1300\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataframes from 'GPT_generated_essays.csv' and 'GPT_generated_essays_1.csv'\n",
    "df_palm1 = pd.read_csv('Palm_generated_texts1.csv')\n",
    "df_palm2 = pd.read_csv('Palm_generated_texts2.csv')\n",
    "df_gpt1 = pd.read_csv('GPT_generated_essays.csv')\n",
    "df_gpt2 = pd.read_csv('GPT_generated_essays_1.csv')\n",
    "\n",
    "# Concatenate the dataframes\n",
    "concatenated_df = pd.concat([df_palm1, df_palm2, df_gpt1, df_gpt2])\n",
    "\n",
    "\n",
    "concatenated_df = concatenated_df[['id', 'prompt_id', 'text', 'generated']].drop_duplicates()\n",
    "\n",
    "# Print the concatenated dataframe\n",
    "print(concatenated_df)\n",
    "\n",
    "print(len(concatenated_df))\n",
    "\n",
    "concatenated_df.to_csv('concat_generated_df.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
